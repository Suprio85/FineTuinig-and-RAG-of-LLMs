{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"archive/Employee_Handbook.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "pages = pages[4:]  \n",
    "text = \"\\n\".join([doc.page_content for doc in pages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "docs = text_splitter.create_documents([text])\n",
    "print(docs)\n",
    "for i, d in enumerate(docs):\n",
    "    d.metadata = {\"doc_id\": i}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "print(API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "# response = model.generate_content(\"Explain how AI works\")\n",
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['GEMINI_API_KEY'] = API_KEY\n",
    "def get_embeddings(text):\n",
    "   \n",
    "    model = 'models/embedding-001'\n",
    "    \n",
    "    embedding = genai.embed_content(model=model,\n",
    "                                    content=text,\n",
    "                                    task_type=\"retrieval_document\")\n",
    "    return embedding['embedding']\n",
    "\n",
    "content_list = [doc.page_content for doc in docs]\n",
    "\n",
    "embeddings = [get_embeddings(content) for content in content_list]\n",
    "\n",
    "\n",
    "dataframe = pd.DataFrame({\n",
    "    'page_content': content_list,\n",
    "    'embeddings': embeddings\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clickhouse_connect\n",
    "client = clickhouse_connect.get_client(\n",
    "      host='msc-0a72ba97.us-east-1.aws.myscale.com',\n",
    "      port=443,\n",
    "      username='suprio85_org_default',\n",
    "      password='passwd_rdoILGlykRQnm4'\n",
    "  )\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<clickhouse_connect.driver.httpclient.HttpClient object at 0x00000175A8180740>\n"
     ]
    }
   ],
   "source": [
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/19 inserted.\n",
      "Batch 2/19 inserted.\n",
      "Batch 3/19 inserted.\n",
      "Batch 4/19 inserted.\n",
      "Batch 5/19 inserted.\n",
      "Batch 6/19 inserted.\n",
      "Batch 7/19 inserted.\n",
      "Batch 8/19 inserted.\n",
      "Batch 9/19 inserted.\n",
      "Batch 10/19 inserted.\n",
      "Batch 11/19 inserted.\n",
      "Batch 12/19 inserted.\n",
      "Batch 13/19 inserted.\n",
      "Batch 14/19 inserted.\n",
      "Batch 15/19 inserted.\n",
      "Batch 16/19 inserted.\n",
      "Batch 17/19 inserted.\n",
      "Batch 18/19 inserted.\n",
      "Batch 19/19 inserted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0', 'chi-msc-0a72ba97-msc-0a72ba97-0-0', 'OK', '0', '0']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a table with the name 'handbook'\n",
    "client.command(\"\"\"\n",
    "    CREATE TABLE default.handbook (\n",
    "        id Int64,\n",
    "        page_content String,\n",
    "        embeddings Array(Float32),\n",
    "        CONSTRAINT check_data_length CHECK length(embeddings) = 768\n",
    "    ) ENGINE = MergeTree()\n",
    "    ORDER BY id\n",
    "\"\"\")\n",
    "\n",
    "# The CONSTRAINT will ensure that the length of each embedding vector is 768\n",
    "\n",
    "# Insert the data in batches\n",
    "batch_size = 10\n",
    "num_batches = len(dataframe) // batch_size\n",
    "for i in range(num_batches):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = start_idx + batch_size\n",
    "    batch_data = dataframe[start_idx:end_idx]\n",
    "    # Insert the data\n",
    "    client.insert(\"default.handbook\", batch_data.to_records(index=False).tolist(), column_names=batch_data.columns.tolist())\n",
    "    print(f\"Batch {i+1}/{num_batches} inserted.\")\n",
    "# Create a vector index for a quick retrieval of data\n",
    "client.command(\"\"\"\n",
    "ALTER TABLE default.handbook\n",
    "    ADD VECTOR INDEX vector_index embeddings\n",
    "    TYPE MSTG\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_docs(user_query):\n",
    "    query_embeddings = get_embeddings(user_query)\n",
    "    results = client.query(f\"\"\"\n",
    "        SELECT page_content,\n",
    "        distance(embeddings, {query_embeddings}) as dist FROM default.handbook ORDER BY dist LIMIT 5\n",
    "    \"\"\")\n",
    "    relevant_docs = []\n",
    "    for row in results.named_results():\n",
    "        relevant_docs.append(row['page_content'])\n",
    "    return relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard work dress code is business casual, which includes conservative and nice clothing like button-down shirts, trousers, blouses, sport coats, and skirts that are knee-length or longer. A tie is not necessary. Every Friday and Saturday employees can dress casually, but their clothes must still be neat and conservative.\n"
     ]
    }
   ],
   "source": [
    "def make_rag_prompt(query, relevant_passage):\n",
    "    relevant_passage = ' '.join(relevant_passage)\n",
    "    prompt = (\n",
    "        f\"You are a helpful and informative chatbot that answers questions using text from the reference passage included below. \"\n",
    "        f\"Respond in a complete sentence and make sure that your response is easy to understand for everyone. \"\n",
    "        f\"Maintain a friendly and conversational tone. If the passage is irrelevant, feel free to ignore it.\\n\\n\"\n",
    "        f\"QUESTION: '{query}'\\n\"\n",
    "        f\"PASSAGE: '{relevant_passage}'\\n\\n\"\n",
    "        f\"ANSWER:\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "\n",
    "\n",
    "def generate_response(user_prompt):\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    answer = model.generate_content(user_prompt)\n",
    "    return answer.text\n",
    "\n",
    "def generate_answer(query):\n",
    "    relevant_text = get_relevant_docs(query)\n",
    "    text = \" \".join(relevant_text)\n",
    "    prompt = make_rag_prompt(query, relevant_passage=relevant_text)\n",
    "    answer = generate_response(prompt)\n",
    "    return answer\n",
    "answer = generate_answer(query=\"what is the Work Dress Code?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The office working hours are as follows: 1) 9:00 am to 5:45 pm or 2) 9:30 am to 6:15 pm.\n"
     ]
    }
   ],
   "source": [
    "answer = generate_answer(query=\"what is the office hours?\")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
